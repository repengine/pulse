"""
output_data_reader.py

Pulse Output Reader â€” unified interface for historical forecast, symbolic, trust, and capital data.

This module parses Pulse-generated output files and memory logs into structured DataFrames
so that meta-analysis modules (e.g., LearningEngine) can perform scoring, mutation, or regression.

Supports:
- Forecast outcome loading
- Symbolic overlay mapping
- Capital performance parsing
- Trust metadata extraction
- Strategos Digest tag access

Author: Pulse v0.299
"""

import os
import json
import pandas as pd
from engine.schemas import (
    ForecastRecord,
    OverlayLog,
    TrustScoreLog,
    CapitalOutcome,
    DigestTag,
)
from pydantic import ValidationError


class OutputDataReader:
    def __init__(self, base_path: str):
        """
        Args:
            base_path (str): Directory root where Pulse outputs and logs are stored
        """
        self.base_path = base_path

    def load_forecast_outputs(self) -> pd.DataFrame:
        """Load all forecast output records into a unified DataFrame."""
        records = []
        forecasts_path = os.path.join(self.base_path, "forecast_output")
        for fname in os.listdir(forecasts_path):
            if fname.endswith(".json"):
                with open(os.path.join(forecasts_path, fname)) as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        records.extend(data)
                    elif isinstance(data, dict):
                        records.append(data)
        valid_records = []
        for rec in records:
            try:
                ForecastRecord(**rec)
                valid_records.append(rec)
            except ValidationError as ve:
                print(f"[OutputDataReader] Invalid forecast record: {ve}")
        return pd.DataFrame(valid_records)

    def load_symbolic_overlays(self) -> pd.DataFrame:
        """Extract symbolic overlays with success/failure attribution."""
        overlay_path = os.path.join(self.base_path, "symbolic_logs")
        data = []
        for fname in os.listdir(overlay_path):
            if fname.endswith(".json"):
                with open(os.path.join(overlay_path, fname)) as f:
                    data.extend(json.load(f))
        valid_data = []
        for rec in data:
            try:
                OverlayLog(**rec)
                valid_data.append(rec)
            except ValidationError as ve:
                print(f"[OutputDataReader] Invalid overlay log: {ve}")
        return pd.DataFrame(valid_data)

    def load_trust_scores(self) -> pd.DataFrame:
        """Load trust scoring metadata per forecast."""
        trust_path = os.path.join(self.base_path, "trust_logs")
        results = []
        for fname in os.listdir(trust_path):
            if fname.endswith(".json"):
                with open(os.path.join(trust_path, fname)) as f:
                    results.extend(json.load(f))
        valid_results = []
        for rec in results:
            try:
                TrustScoreLog(**rec)
                valid_results.append(rec)
            except ValidationError as ve:
                print(f"[OutputDataReader] Invalid trust score log: {ve}")
        return pd.DataFrame(valid_results)

    def load_capital_outcomes(self) -> pd.DataFrame:
        """Aggregate capital simulation results per scenario."""
        capital_path = os.path.join(self.base_path, "capital_output")
        outputs = []
        for fname in os.listdir(capital_path):
            if fname.endswith(".json"):
                with open(os.path.join(capital_path, fname)) as f:
                    outputs.extend(json.load(f))
        valid_outputs = []
        for rec in outputs:
            try:
                CapitalOutcome(**rec)
                valid_outputs.append(rec)
            except ValidationError as ve:
                print(f"[OutputDataReader] Invalid capital outcome: {ve}")
        return pd.DataFrame(valid_outputs)

    def load_digest_tags(self) -> pd.DataFrame:
        """Pull Strategos Digest tags or narrative summaries."""
        tag_path = os.path.join(self.base_path, "digest_logs")
        tags = []
        for fname in os.listdir(tag_path):
            if fname.endswith(".json"):
                with open(os.path.join(tag_path, fname)) as f:
                    tags.extend(json.load(f))
        valid_tags = []
        for rec in tags:
            try:
                DigestTag(**rec)
                valid_tags.append(rec)
            except ValidationError as ve:
                print(f"[OutputDataReader] Invalid digest tag: {ve}")
        return pd.DataFrame(valid_tags)

    def get_all_metadata(self) -> pd.DataFrame:
        """
        Merge all subsystems' data on scenario ID or timestamp if present.
        Returns a master DataFrame for learning engines to analyze.
        """
        try:
            df_f = self.load_forecast_outputs()
            df_s = self.load_symbolic_overlays()
            df_t = self.load_trust_scores()
            df_c = self.load_capital_outcomes()
            df_d = self.load_digest_tags()
            df = (
                df_f.merge(df_s, how="left", on="scenario_id")
                .merge(df_t, how="left", on="scenario_id")
                .merge(df_c, how="left", on="scenario_id")
                .merge(df_d, how="left", on="scenario_id")
            )
            return df
        except Exception as e:
            print(f"[OutputDataReader] Metadata merge failed: {e}")
            return pd.DataFrame()


# Market, social, ecological data loaders for feature engineering
def load_market_data() -> pd.DataFrame:
    """
    Load market data for feature engineering.
    Reads CSV files from irldata/market_data directory.
    """
    base_dir = os.path.dirname(os.path.dirname(__file__))
    data_dir = os.path.join(base_dir, "irldata", "market_data")
    dfs = []
    if os.path.isdir(data_dir):
        for fname in os.listdir(data_dir):
            if fname.endswith(".csv"):
                try:
                    df = pd.read_csv(os.path.join(data_dir, fname))
                    dfs.append(df)
                except Exception as e:
                    print(
                        f"[OutputDataReader] Error reading market data file {fname}: {e}"
                    )
    if dfs:
        return pd.concat(dfs, ignore_index=True)
    return pd.DataFrame()


def load_social_data() -> pd.DataFrame:
    """
    Load social data (e.g., sentiment, engagement) for feature engineering.
    Reads CSV files from irldata/social_data directory.
    """
    base_dir = os.path.dirname(os.path.dirname(__file__))
    data_dir = os.path.join(base_dir, "irldata", "social_data")
    dfs = []
    if os.path.isdir(data_dir):
        for fname in os.listdir(data_dir):
            if fname.endswith(".csv"):
                try:
                    df = pd.read_csv(os.path.join(data_dir, fname))
                    dfs.append(df)
                except Exception as e:
                    print(
                        f"[OutputDataReader] Error reading social data file {fname}: {e}"
                    )
    if dfs:
        return pd.concat(dfs, ignore_index=True)
    return pd.DataFrame()


def load_ecological_data() -> pd.DataFrame:
    """
    Load ecological data (e.g., environmental indicators) for feature engineering.
    Reads CSV files from irldata/ecological_data directory.
    """
    base_dir = os.path.dirname(os.path.dirname(__file__))
    data_dir = os.path.join(base_dir, "irldata", "ecological_data")
    dfs = []
    if os.path.isdir(data_dir):
        for fname in os.listdir(data_dir):
            if fname.endswith(".csv"):
                try:
                    df = pd.read_csv(os.path.join(data_dir, fname))
                    dfs.append(df)
                except Exception as e:
                    print(
                        f"[OutputDataReader] Error reading ecological data file {fname}: {e}"
                    )
    if dfs:
        return pd.concat(dfs, ignore_index=True)
    return pd.DataFrame()
